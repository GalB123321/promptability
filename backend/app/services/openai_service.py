"""
Contains the service logic to connect to OpenAI's GPT API.
Takes raw text input plus the user's profile (for relationship purposes only)
and returns a crafted, optimized prompt generated by the model.
Profile content is not considered in the prompt generation.
"""

import os
import logging
from typing import Dict, Any, Optional, List
from openai import OpenAI, APIError, RateLimitError

from app.models.promptability import Prompt

# Configure logging
logger = logging.getLogger(__name__)

# Get API key and default model from environment variables
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
API_KEY = os.getenv("OPENAI_API_KEY")

# Available OpenAI models for prompt engineering
AVAILABLE_MODELS = [
    "gpt-4o", 
    "gpt-4-turbo", 
    "gpt-3.5-turbo"
]

# Initialize the OpenAI client
try:
    client = OpenAI(api_key=API_KEY)
except Exception as e:
    logger.error(f"Failed to initialize OpenAI client: {str(e)}")
    client = None


def _create_system_message() -> str:
    """Create the system message for prompt engineering"""
    return (
        "You are an expert prompt engineer. "
        "Craft clear, concise prompts for other AI models based on user input. "
        "Focus on generating prompts that will produce high-quality responses "
        "optimized for the target platform."
    )


def _get_platform_specific_instructions(platform_id: str) -> str:
    """
    Get platform-specific instructions for prompt formatting
    
    Args:
        platform_id: Target AI platform ID
        
    Returns:
        Platform-specific instructions string
    """
    platform = platform_id.lower() if platform_id else "default"
    
    # Common platform-specific instructions
    instructions = {
        "chatgpt": (
            "For ChatGPT, create a prompt that:\n"
            "1. Is clear and specific\n"
            "2. Provides necessary context\n"
            "3. Includes specific instructions on output format if needed\n"
            "4. Uses step-by-step direction for complex tasks"
        ),
        "claude": (
            "For Claude, create a prompt that:\n"
            "1. Uses XML tags for structured instructions when appropriate\n"
            "2. Provides examples for format guidance\n"
            "3. Specifies the desired tone and level of detail\n"
            "4. Uses conversational language"
        ),
        "gemini": (
            "For Gemini, create a prompt that:\n"
            "1. Is direct and specific\n"
            "2. Includes examples for complex requirements\n"
            "3. Breaks down multi-part questions clearly\n"
            "4. Specifies if code examples are needed"
        ),
        "default": (
            "Create a prompt that:\n"
            "1. Is optimized for the target AI platform\n"
            "2. Is clear and specific about what is requested\n"
            "3. Will generate the most helpful response for the selected text\n"
            "4. Uses any special syntax or formatting specific to the target platform"
        )
    }
    
    return instructions.get(platform, instructions["default"])


def _create_user_message(
    prompt_data: Prompt, 
    profile: Dict[str, Any]  # Keep this parameter for compatibility with existing code
) -> str:
    """
    Create the user message with only essential context, ignoring profile content
    """
    # Build the message components
    message_parts = [f"Selected Text:\n\"{prompt_data.selectedText}\"\n"]
    
    # Add explicit instruction to ignore profile
    message_parts.append(
        "IMPORTANT: Focus only on the specific request text itself. "
        "Do not incorporate any professional background, industry knowledge, or user profile characteristics."
    )
    
    # Add role and industry if available - these come from the prompt data, not the profile
    role_industry = []
    if hasattr(prompt_data, "roleId") and prompt_data.roleId:
        role_industry.append(f"Role: {prompt_data.roleId}")
    if hasattr(prompt_data, "industryId") and prompt_data.industryId:
        role_industry.append(f"Industry: {prompt_data.industryId}")
    
    role_industry_str = ", ".join(role_industry)
    if role_industry_str:
        message_parts.append(role_industry_str)
    
    # Add platform information
    message_parts.append(f"Target Platform: {prompt_data.platformId}")
    
    # Add formatting options information
    if hasattr(prompt_data, "formattingOptions"):
        format_options = []
        append_instructions = getattr(prompt_data.formattingOptions, "appendInstructions", False)
        should_truncate = getattr(prompt_data.formattingOptions, "shouldTruncate", False)
        
        if append_instructions:
            format_options.append("Include clear instructions in the prompt")
        
        if should_truncate:
            format_options.append("Keep the prompt concise and focused")
        
        if format_options:
            message_parts.append(f"Formatting Requirements: {', '.join(format_options)}")
    
    # Add platform-specific instructions
    message_parts.append(_get_platform_specific_instructions(prompt_data.platformId))
    
    # Add final instruction
    message_parts.append("Please output only the final prompt text.")
    
    # Join all parts with double newlines
    return "\n\n".join(message_parts)

def generate_prompt_text(
    p: Prompt, 
    profile: dict[str, any],  # Keep parameter for compatibility with existing code
    model: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 300
) -> str:
    """
    Generate an optimized prompt text for the target AI platform.
    Accepts profile for compatibility but doesn't use its content.
    
    Args:
        p: Prompt object containing the selected text and context
        profile: User profile information (kept for API compatibility but content ignored)
        model: Specific OpenAI model to use (if None, uses default)
        temperature: Creativity setting (0.0-1.0)
        max_tokens: Maximum response length
        
    Returns:
        Generated prompt text
        
    Raises:
        ValueError: If OpenAI client is not initialized or model is invalid
        Exception: For API errors or other issues
    """
    if not client:
        raise ValueError("OpenAI client not initialized. Check your API key.")
    
    # Validate and select model
    selected_model = model if model in AVAILABLE_MODELS else DEFAULT_MODEL
    logger.info(f"Using model: {selected_model}, profile content consideration: disabled")
    
    # Create messages
    system_msg = _create_system_message()
    user_msg = _create_user_message(p, profile)  # Pass profile for consistency but content not used
    
    try:
        # Call the OpenAI API
        response = client.chat.completions.create(
            model=selected_model,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        
        # Extract and return the generated prompt
        return response.choices[0].message.content.strip()
    
    except RateLimitError as e:
        logger.error(f"OpenAI rate limit exceeded: {str(e)}")
        raise Exception("Rate limit exceeded. Please try again later.")
    
    except APIError as e:
        logger.error(f"OpenAI API error: {str(e)}")
        raise Exception(f"API error: {str(e)}")
    
    except Exception as e:
        logger.error(f"Error generating prompt: {str(e)}")
        raise


def get_available_models() -> List[str]:
    """
    Get all available OpenAI models for prompt engineering.
    
    Returns:
        List of available model names
    """
    return AVAILABLE_MODELS